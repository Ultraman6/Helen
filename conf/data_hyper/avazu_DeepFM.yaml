model:
  model: DeepFM
  batch_norm: False
  hidden_units: [ 2000, 2000, 2000, 2000 ]
  hidden_activations: relu
  embedding_dim: 16
  embedding_dropout: 0
  embedding_regularizer: 0
  net_dropout: 0
  net_regularizer: 0


optim:
  max_grad_norm: 10.0
  lr: 0.001
  lr_decay: False
  gamma: 0.1
  min_lr: 1e-6
  warmup_steps: -1
